{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Identifying False Friends - Words with Similar Spelling but Different Semantics\n",
    "\n",
    "In this task, the goal is to identify pairs of words that have similar or identical spellings but different semantic meanings. This is often referred to as identifying \"false friends.\"\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "- Read pairs of English and Spanish words from a CSV file.\n",
    "- Determine whether each pair of words is a potential \"false friend\" based on semantic similarity and spelling.\n",
    "- Print the results indicating whether the words are potential false friends or not.\n",
    "\n",
    "### Problem\n",
    "\n",
    "The problem being addressed is the identification of pairs of words that look similar but have different meanings in English and Spanish. The solution should use various techniques, including Levenshtein distance and word embeddings, to make this determination.\n",
    "\n",
    "### Solution\n",
    "\n",
    "**you need to create a file .env which contains your babelnet api key to use this.**\n",
    "\n",
    "The solution involves the following steps:\n",
    "\n",
    "#### Reading Pairs of Words from CSV\n",
    "\n",
    "1. Open and read a CSV file containing pairs of English and Spanish words. The CSV file is specified by the `csv_file_path` variable.\n",
    "2. Create a list of tuples, `translation_tuples`, to store the word pairs.\n",
    "\n",
    "#### Identifying False Friends\n",
    "\n",
    "1. Define a function `words_overlap` that calculates the Levenshtein distance between two words and returns `True` if the distance is less than or equal to a threshold (half of the maximum word length). This function helps identify similar spellings.\n",
    "2. Define a function `count_overlapping_words` that counts the number of overlapping words between two meanings. It tokenizes the meanings, normalizes them to lowercase, and counts overlapping words.\n",
    "3. Define a function `is_false_friend` that takes a pair of words and determines if they are potential false friends. It performs the following steps:\n",
    "   - Checks if the words have overlapping spellings using `words_overlap`.\n",
    "   - Retrieves the meanings of the words in English and Spanish using PyMultiDictionary and Babelnet for the second approch.\n",
    "   - Normalizes the meanings to lowercase and computes the semantic similarity between the meanings using word embeddings.\n",
    "   - Considers words potential false friends if they have similar spellings or if their semantic similarity is below a threshold (0.80).\n",
    "\n",
    "#### Printing Results\n",
    "\n",
    "1. Iterate through the list of word pairs from `translation_tuples`.\n",
    "2. Call the `is_false_friend` function for each pair to determine if they are potential false friends.\n",
    "3. Print the results, indicating whether the words are potential false friends or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 10:48:31.232189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-09 10:48:32.484237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import Levenshtein\n",
    "from nltk.corpus import wordnet\n",
    "from translate import Translator\n",
    "# python -m spacy download en_core_web_md\n",
    "import spacy\n",
    "import requests\n",
    "import json\n",
    "from translate import Translator\n",
    "from PyMultiDictionary import MultiDictionary\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "dictionary = MultiDictionary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Actual', 'Actual'), ('Parent', 'Pariente'), ('Library', 'Librería'), ('Pretend', 'Pretender'), ('Sympathy', 'Simpatía'), ('Embarrassed', 'Embarazada'), ('Carpet', 'Carpeta'), ('Fabricate', 'Fabricar'), ('Actualize', 'Actualizar'), ('Sensation', 'Sensación'), ('Mayor', 'Mayor'), ('Excited', 'Excitado'), ('Intoxicated', 'Intoxicado'), ('Fabrication', 'Fabricación'), ('Casual', 'Casual'), ('Resume', 'Resumir'), ('Familiar', 'Familiar'), ('Pretend', 'Pretender'), ('Sensible', 'Sensible'), ('College', 'Colegio'), ('Education', 'Educación'), ('Introduce', 'Introducir'), ('Deception', 'Decepción'), ('Artist', 'Artista'), ('Accident', 'Accidente'), ('Parental', 'Parental'), ('Editor', 'Editor'), ('Eventually', 'Eventualmente')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = '../lab6/false_friends.csv'\n",
    "\n",
    "# Initialize an empty list to store the tuples\n",
    "translation_tuples = []\n",
    "\n",
    "# Open the CSV file and read its contents\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    # Skip the header row\n",
    "    next(csvreader)\n",
    "    \n",
    "    # Iterate through the rows and create tuples\n",
    "    for row in csvreader:\n",
    "        if len(row) == 2:\n",
    "            english_word, spanish_word = row\n",
    "            translation_tuples.append((english_word.strip(), spanish_word.strip()))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(translation_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_overlap(word1, word2):\n",
    "    \"\"\"\n",
    "    Determine if two words overlap based on a similarity threshold.\n",
    "\n",
    "    Args:\n",
    "        word1 (str): The first word.\n",
    "        word2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the words overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    threshold = int(0.5 * max(len(word1), len(word2)))\n",
    "    distance = Levenshtein.distance(word1, word2)\n",
    "    return distance <= threshold\n",
    "\n",
    "def count_overlapping_words(meaning1, meaning2):\n",
    "    \"\"\"\n",
    "    Count the number of overlapping words between two meanings.\n",
    "\n",
    "    Args:\n",
    "        meaning1 (str): The first meaning.\n",
    "        meaning2 (str): The second meaning.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of overlapping words.\n",
    "    \"\"\"\n",
    "    tokens1 = set(meaning1.lower().split())\n",
    "    tokens2 = set(meaning2.lower().split())\n",
    "    overlap = tokens1.intersection(tokens2)\n",
    "    return len(overlap)\n",
    "\n",
    "def is_false_friend(word1, word2):\n",
    "    \"\"\"\n",
    "    Check if two words are false friends.\n",
    "\n",
    "    Args:\n",
    "        word1 (str): The first word.\n",
    "        word2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the words are false friends, False otherwise.\n",
    "    \"\"\"\n",
    "    print(word1, word2)\n",
    "\n",
    "    if words_overlap(word1.lower(), word2.lower()):\n",
    "        translated_meaning1 = dictionary.meaning('en', word1)\n",
    "        translated_meaning2 = dictionary.meaning('es', word2)\n",
    "\n",
    "        token1 = nlp(translated_meaning1[1].lower())  # Normalize to lowercase\n",
    "        token2 = nlp(translated_meaning2[1].lower())  # Normalize to lowercase\n",
    "\n",
    "        # If meanings are not found for either word, consider them potential false friends\n",
    "        if len(translated_meaning2[0]) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            if token1.similarity(token2) < 0.80:\n",
    "                return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Actual\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word1 'Actual', Word2 'Actual\n",
      "Potential false friends.\n",
      "\n",
      "Parent Pariente\n",
      "Word1 'Parent', Word2 'Pariente\n",
      "Potential false friends.\n",
      "\n",
      "Library Librería\n",
      "Word1 'Library', Word2 'Librería\n",
      "Potential false friends.\n",
      "\n",
      "Pretend Pretender\n",
      "Word1 'Pretend', Word2 'Pretender\n",
      "Potential false friends.\n",
      "\n",
      "Sympathy Simpatía\n",
      "Word1 'Sympathy', Word2 'Simpatía\n",
      "Potential false friends.\n",
      "\n",
      "Embarrassed Embarazada\n",
      "Word1 'Embarrassed', Word2 'Embarazada\n",
      "Potential false friends.\n",
      "\n",
      "Carpet Carpeta\n",
      "Word1 'Carpet', Word2 'Carpeta\n",
      "Potential false friends.\n",
      "\n",
      "Fabricate Fabricar\n",
      "Word1 'Fabricate', Word2 'Fabricar\n",
      "Potential false friends.\n",
      "\n",
      "Actualize Actualizar\n",
      "Word1 'Actualize', Word2 'Actualizar\n",
      "Potential false friends.\n",
      "\n",
      "Sensation Sensación\n",
      "Word1 'Sensation', Word2 'Sensación\n",
      "Potential false friends.\n",
      "\n",
      "Mayor Mayor\n",
      "Word1 'Mayor', Word2 'Mayor\n",
      "Potential false friends.\n",
      "\n",
      "Excited Excitado\n",
      "Word1 'Excited', Word2 'Excitado\n",
      "Potential false friends.\n",
      "\n",
      "Intoxicated Intoxicado\n",
      "Word1 'Intoxicated', Word2 'Intoxicado\n",
      "Potential false friends.\n",
      "\n",
      "Fabrication Fabricación\n",
      "Word1 'Fabrication', Word2 'Fabricación\n",
      "Potential false friends.\n",
      "\n",
      "Casual Casual\n",
      "Word1 'Casual', Word2 'Casual\n",
      "Potential false friends.\n",
      "\n",
      "Resume Resumir\n",
      "Word1 'Resume', Word2 'Resumir\n",
      "Potential false friends.\n",
      "\n",
      "Familiar Familiar\n",
      "Word1 'Familiar', Word2 'Familiar\n",
      "Potential false friends.\n",
      "\n",
      "Pretend Pretender\n",
      "Word1 'Pretend', Word2 'Pretender\n",
      "Potential false friends.\n",
      "\n",
      "Sensible Sensible\n",
      "Word1 'Sensible', Word2 'Sensible\n",
      "Potential false friends.\n",
      "\n",
      "College Colegio\n",
      "Word1 'College', Word2 'Colegio\n",
      "Potential false friends.\n",
      "\n",
      "Education Educación\n",
      "Word1 'Education', Word2 'Educación\n",
      "Potential false friends.\n",
      "\n",
      "Introduce Introducir\n",
      "Word1 'Introduce', Word2 'Introducir\n",
      "Potential false friends.\n",
      "\n",
      "Deception Decepción\n",
      "Word1 'Deception', Word2 'Decepción\n",
      "Potential false friends.\n",
      "\n",
      "Artist Artista\n",
      "Word1 'Artist', Word2 'Artista\n",
      "Potential false friends.\n",
      "\n",
      "Accident Accidente\n",
      "Word1 'Accident', Word2 'Accidente\n",
      "Potential false friends.\n",
      "\n",
      "Parental Parental\n",
      "Word1 'Parental', Word2 'Parental\n",
      "NOT false friends.\n",
      "\n",
      "Editor Editor\n",
      "Word1 'Editor', Word2 'Editor\n",
      "NOT false friends.\n",
      "\n",
      "Eventually Eventualmente\n",
      "Word1 'Eventually', Word2 'Eventualmente\n",
      "NOT false friends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in translation_tuples:\n",
    "    if is_false_friend(x, y):\n",
    "        print(f\"Word1 '{x}', Word2 '{y}\")\n",
    "        print(\"Potential false friends.\")\n",
    "        print()  # Add a blank line between each iteration\n",
    "    else:\n",
    "        print(f\"Word1 '{x}', Word2 '{y}\")\n",
    "        print(\"NOT false friends.\")\n",
    "        print()  # Add a blank line between each iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Actual\n",
      "Word1 'Actual', Word2 'Actual\n",
      "Potential false friends.\n",
      "\n",
      "Parent Pariente\n",
      "Word1 'Parent', Word2 'Pariente\n",
      "NOT false friends.\n",
      "\n",
      "Library Librería\n",
      "Word1 'Library', Word2 'Librería\n",
      "Potential false friends.\n",
      "\n",
      "Pretend Pretender\n",
      "Word1 'Pretend', Word2 'Pretender\n",
      "Potential false friends.\n",
      "\n",
      "Sympathy Simpatía\n",
      "Word1 'Sympathy', Word2 'Simpatía\n",
      "NOT false friends.\n",
      "\n",
      "Embarrassed Embarazada\n",
      "Word1 'Embarrassed', Word2 'Embarazada\n",
      "Potential false friends.\n",
      "\n",
      "Carpet Carpeta\n",
      "Word1 'Carpet', Word2 'Carpeta\n",
      "Potential false friends.\n",
      "\n",
      "Fabricate Fabricar\n",
      "Word1 'Fabricate', Word2 'Fabricar\n",
      "Potential false friends.\n",
      "\n",
      "Actualize Actualizar\n",
      "Word1 'Actualize', Word2 'Actualizar\n",
      "Potential false friends.\n",
      "\n",
      "Sensation Sensación\n",
      "Word1 'Sensation', Word2 'Sensación\n",
      "NOT false friends.\n",
      "\n",
      "Mayor Mayor\n",
      "Word1 'Mayor', Word2 'Mayor\n",
      "Potential false friends.\n",
      "\n",
      "Excited Excitado\n",
      "Word1 'Excited', Word2 'Excitado\n",
      "Potential false friends.\n",
      "\n",
      "Intoxicated Intoxicado\n",
      "Word1 'Intoxicated', Word2 'Intoxicado\n",
      "Potential false friends.\n",
      "\n",
      "Fabrication Fabricación\n",
      "Word1 'Fabrication', Word2 'Fabricación\n",
      "Potential false friends.\n",
      "\n",
      "Casual Casual\n",
      "Word1 'Casual', Word2 'Casual\n",
      "Potential false friends.\n",
      "\n",
      "Resume Resumir\n",
      "Word1 'Resume', Word2 'Resumir\n",
      "NOT false friends.\n",
      "\n",
      "Familiar Familiar\n",
      "Word1 'Familiar', Word2 'Familiar\n",
      "Potential false friends.\n",
      "\n",
      "Pretend Pretender\n",
      "Word1 'Pretend', Word2 'Pretender\n",
      "Potential false friends.\n",
      "\n",
      "Sensible Sensible\n",
      "Word1 'Sensible', Word2 'Sensible\n",
      "NOT false friends.\n",
      "\n",
      "College Colegio\n",
      "Word1 'College', Word2 'Colegio\n",
      "Potential false friends.\n",
      "\n",
      "Education Educación\n",
      "Word1 'Education', Word2 'Educación\n",
      "Potential false friends.\n",
      "\n",
      "Introduce Introducir\n",
      "Word1 'Introduce', Word2 'Introducir\n",
      "Potential false friends.\n",
      "\n",
      "Deception Decepción\n",
      "Word1 'Deception', Word2 'Decepción\n",
      "Potential false friends.\n",
      "\n",
      "Artist Artista\n",
      "Word1 'Artist', Word2 'Artista\n",
      "Potential false friends.\n",
      "\n",
      "Accident Accidente\n",
      "Word1 'Accident', Word2 'Accidente\n",
      "Potential false friends.\n",
      "\n",
      "Parental Parental\n",
      "Word1 'Parental', Word2 'Parental\n",
      "NOT false friends.\n",
      "\n",
      "Editor Editor\n",
      "Word1 'Editor', Word2 'Editor\n",
      "NOT false friends.\n",
      "\n",
      "Eventually Eventualmente\n",
      "Word1 'Eventually', Word2 'Eventualmente\n",
      "NOT false friends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "def get_synset_meaning(synset_id):\n",
    "    \"\"\"\n",
    "    Get the meaning of a synset based on its ID.\n",
    "\n",
    "    Args:\n",
    "        synset_id (str): The ID of the synset.\n",
    "\n",
    "    Returns:\n",
    "        str: The meaning of the synset.\n",
    "    \"\"\"\n",
    "    url = f\"https://babelnet.io/v8/getSynset?id={synset_id}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.text)\n",
    "    return data['glosses'][0]['gloss'] if 'glosses' in data and data['glosses'] else ''\n",
    "\n",
    "\n",
    "def get_word_meaning(word, lang):\n",
    "    \"\"\"\n",
    "    Get the meaning of a word in a specific language.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word.\n",
    "        lang (str): The language code.\n",
    "\n",
    "    Returns:\n",
    "        str: The meaning of the word.\n",
    "    \"\"\"\n",
    "    url = f\"https://babelnet.io/v8/getSynsetIds?lemma={word}&searchLang={lang}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    synset_ids = json.loads(response.text)\n",
    "    for synset_id in synset_ids:\n",
    "        meaning = get_synset_meaning(synset_id['id'])\n",
    "        if meaning:\n",
    "            return meaning\n",
    "    return ''\n",
    "\n",
    "def words_overlap(word1, word2):\n",
    "    \"\"\"\n",
    "    Determine if two words overlap based on a similarity threshold.\n",
    "\n",
    "    Args:\n",
    "        word1 (str): The first word.\n",
    "        word2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the words overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    threshold = int(0.5 * max(len(word1), len(word2)))\n",
    "    distance = Levenshtein.distance(word1, word2)\n",
    "    return distance <= threshold\n",
    "\n",
    "def count_overlapping_words(meaning1, meaning2):\n",
    "    \"\"\"\n",
    "    Count the number of overlapping words between two meanings.\n",
    "\n",
    "    Args:\n",
    "        meaning1 (str): The first meaning.\n",
    "        meaning2 (str): The second meaning.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of overlapping words.\n",
    "    \"\"\"\n",
    "    tokens1 = set(meaning1.lower().split())\n",
    "    tokens2 = set(meaning2.lower().split())\n",
    "    overlap = tokens1.intersection(tokens2)\n",
    "    return len(overlap)\n",
    "\n",
    "def is_false_friend(word1, word2):\n",
    "    \"\"\"\n",
    "    Check if two words are false friends.\n",
    "\n",
    "    Args:\n",
    "        word1 (str): The first word.\n",
    "        word2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the words are false friends, False otherwise.\n",
    "    \"\"\"\n",
    "    print(word1, word2)\n",
    "\n",
    "    if words_overlap(word1.lower(), word2.lower()):\n",
    "        token1 = nlp(word1.lower())  # Normalize to lowercase\n",
    "        token2 = nlp(word2.lower())  # Normalize to lowercase\n",
    "\n",
    "        # Tokenize and lemmatize the word\n",
    "        lemma1 = token1[0].lemma_\n",
    "        lemma2 = token2[0].lemma_\n",
    "\n",
    "        translated_meaning1 = get_word_meaning(lemma1,\"EN\")\n",
    "        translated_meaning2 = get_word_meaning(lemma2,\"ES\")\n",
    "\n",
    "        tokenized_meaning1 = nlp(translated_meaning1.lower())\n",
    "        tokenized_meaning2 = nlp(translated_meaning2.lower())\n",
    "\n",
    "        # If meanings are not found for either word, consider them potential false friends\n",
    "        if tokenized_meaning1.similarity(tokenized_meaning2) <  0.80:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return False\n",
    "\n",
    "for x, y in translation_tuples:\n",
    "    if is_false_friend(x, y):\n",
    "        print(f\"Word1 '{x}', Word2 '{y}\")\n",
    "        print(\"Potential false friends.\")\n",
    "        print()  # Add a blank line between each iteration\n",
    "    else:\n",
    "        print(f\"Word1 '{x}', Word2 '{y}\")\n",
    "        print(\"NOT false friends.\")\n",
    "        print()  # Add a blank line between each iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
